# Deep-learning-lab2-CNN-ViT
# Deep Learning Lab 2 - Comparaison d'architectures sur MNIST

**Auteur :** [Votre Nom]  
**Sujet :** Exploration de CNN classique, Faster R-CNN et Transfer Learning sur le dataset MNIST  

## ğŸ“Œ Introduction

Lâ€™objectif de ce laboratoire Ã©tait dâ€™explorer et de comparer diffÃ©rentes approches architecturales pour la classification dâ€™images sur le dataset MNIST :

- Un CNN classique (baseline)
- Un modÃ¨le de dÃ©tection dâ€™objets Faster R-CNN dÃ©tournÃ© pour faire de la classification
- Des approches de Transfer Learning avec VGG16 et AlexNet

Ce README rÃ©sume la dÃ©marche, les implÃ©mentations clÃ©s et lâ€™analyse des rÃ©sultats obtenus.

---

## 1. CNN Classique (Baseline)

### ğŸ§  Approche
Architecture lÃ©gÃ¨re avec extraction de caractÃ©ristiques locales (convolutions) + rÃ©duction de dimensionnalitÃ© (max pooling).

### ğŸ’» Structure principale
```python
self.conv_layers = nn.Sequential(
    nn.Conv2d(1, 32, kernel_size=3, padding=1),
    nn.ReLU(),
    nn.MaxPool2d(2),
    nn.Conv2d(32, 64, kernel_size=3, padding=1),
    nn.ReLU(),
    nn.MaxPool2d(2)
)
ğŸ“Š RÃ©sultats





















MÃ©triqueValeurAccuracy (test)99.01 %Temps dâ€™entraÃ®nement73.5 s (5 Ã©poques)Loss finale0.032
Observation : Convergence extrÃªmement rapide. Sur MNIST (images 28Ã—28 centrÃ©es), un CNN lÃ©ger atteint presque la perfection.

2. Faster R-CNN (DÃ©tection dâ€™objet â†’ Classification)
ğŸ§  Approche
Utilisation dâ€™un dÃ©tecteur dâ€™objets (backbone ResNet50 + FPN + RPN) en considÃ©rant chaque chiffre comme un unique Â« objet Â» Ã  localiser.
ğŸ’» Point clÃ© : crÃ©ation de bounding boxes automatiques
Pythonnon_zero = torch.nonzero(img_tensor.squeeze())
x_min, x_max = torch.min(non_zero[:, 1]).item(), torch.max(non_zero[:, 1]).item()
y_min, y_max = torch.min(non_zero[:, 0]).item(), torch.max(non_zero[:, 0]).item()

target["boxes"] = torch.as_tensor([[x_min, y_min, x_max+1, y_max+1]], dtype=torch.float32)
target["labels"] = torch.as_tensor([label + 1], dtype=torch.int64)  # +1 car 0 = background
ğŸ“Š RÃ©sultats

















MÃ©triqueValeurAccuracy (test)94.80 %Temps dâ€™entraÃ®nement778 s (~13 min)
Observation critique : Ã—10 plus lent que le CNN simple, et moins prÃ©cis.
Verdict : Totalement overkill pour une tÃ¢che oÃ¹ la localisation est triviale.

3. Transfer Learning (VGG16 & AlexNet)
ğŸ§  Approche
ModÃ¨les prÃ©-entraÃ®nÃ©s ImageNet â†’ adaptation Ã  MNIST (grayscale 28Ã—28 â†’ RGB 224Ã—224).
ğŸ’» Transformations & freeze
Pythontransform_tl = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.Grayscale(num_output_channels=3),
    transforms.ToTensor()
])

# Freeze des couches convolutionnelles
for param in vgg16.parameters():
    param.requires_grad = False

# Remplacement de la tÃªte
num_ftrs = vgg16.classifier[6].in_features
vgg16.classifier[6] = nn.Linear(num_ftrs, 10)
ğŸ“Š RÃ©sultats (loss sur 5 Ã©poques)

















ModÃ¨leLoss initiale â†’ finaleVGG161.36 â†’ 0.74AlexNet0.94 â†’ 0.49
Observation : EntraÃ®nement trÃ¨s lourd Ã  cause de lâ€™upscaling Ã—64 des images. Gain de performance nÃ©gligeable vs CNN natif.

ğŸ† SynthÃ¨se Globale





























ModÃ¨leAccuracyTemps (5 Ã©poques)VerdictCNN Standard99.01 %73.5 sâœ… Optimal â€“ meilleur ratio perf/coÃ»tFaster R-CNN94.80 %778 sâŒ InadaptÃ© â€“ trop complexeTransfer Learning~98-99 %TrÃ¨s Ã©levÃ©âš ï¸ CoÃ»teux â€“ upscaling pÃ©nalisant

ğŸ¯ Conclusion du Laboratoire
La complexitÃ© dâ€™un modÃ¨le ne garantit jamais de meilleures performances.
Sur un dataset simple et bien structurÃ© comme MNIST :
Un CNN lÃ©ger et dÃ©diÃ© surpasse largement largement des architectures massifs (Faster R-CNN, VGG16 prÃ©-entraÃ®nÃ©) tant en prÃ©cision quâ€™en vitesse.
Ce lab illustre parfaitement le principe : "Choose the right tool for the job".